{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Story`\n",
    "\n",
    "You have to implement decision trees from scratch without using any pre built fucntion.\n",
    "You teacher has given you a text file as assignement to check the accuracy of the tree you've built.\n",
    "You ask your cousin brother Adi for help, who is very proficient with Mathematical Models.\n",
    "\n",
    "The `data` contains the details of 1372 banknotes. The data set contained four features and one label, in a form of CSV. Data was extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n",
    "\n",
    "He explains you the basics behind a decision tree first, and briefs you about Decision Trees.\n",
    "\n",
    "A `decision tree` is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
    "\n",
    "A decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "\n",
    "Tree based learning algorithms are considered to be one of the best and mostly used supervised learning methods. Tree based methods empower predictive models with high accuracy, stability and ease of interpretation. Unlike linear models, they map non-linear relationships quite well. They are adaptable at solving any kind of problem at hand (classification or regression). Decision Tree algorithms are referred to as CART (Classification and Regression Trees).\n",
    "\n",
    "A tree has many analogies in real life, and turns out that it has influenced a wide area of machine learning, covering both classification and regression. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. As the name goes, it uses a tree-like model of decisions. Though a commonly used tool in data mining for deriving a strategy to reach a particular goal, its also widely used in machine learning, which will be the main focus of this article.\n",
    "How can an algorithm be represented as a tree?\n",
    "\n",
    "The methodology is more commonly known as learning decision tree from data and above tree is called Classification tree as the target is to classify passenger as survived or died. Regression trees are represented in the same manner, just they predict continuous values like price of a house. In general, Decision Tree algorithms are referred to as CART or Classification and Regression Trees.\n",
    "\n",
    "\n",
    "`Applications for Decision Tree :`\n",
    "\n",
    "Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure. They also are well suited to categorization problems where attributes or features are systematically checked to determine a final category. For example, a decision tree could be used effectively to determine the species of an animal.\n",
    "\n",
    "\n",
    "\n",
    "First, Adi asks you to save the datafile in a variable to access it, and as per your teacher's instruction, you are supposed to set\n",
    "    \n",
    "    n_folds =20\n",
    "    max_depth = 10\n",
    "    min_size = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "filename = 'data.txt'\n",
    "#hyperparameters of the algorithm\n",
    "n_folds =20\n",
    "max_depth = 10\n",
    "min_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Story`\n",
    "Now, Adi asks you to make the function for splitting the data in k folds.\n",
    "\n",
    "# Helper Function\n",
    "`How?`\n",
    "\n",
    "This requires splitting the items and shuffling them in the folds.\n",
    "\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "    Shuffle the dataset randomly.\n",
    "    Split the dataset into k groups\n",
    "    For each unique group:\n",
    "        Take the group as a hold out or test data set\n",
    "        Take the remaining groups as a training data set\n",
    "        Fit a model on the training set and evaluate it on the test set\n",
    "        Retain the evaluation score and discard the model\n",
    "    Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "Importantly, each observation in the data sample is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How?`\n",
    "\n",
    "`def k_fold_cross_validation(items, randomize=False):`\n",
    "\n",
    "Splits the data in k folds and returns the concatenated data. The advantage of this method over repeated random sub-sampling (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits the data in k folds and returns the concatenated data\n",
    "def k_fold_cross_validation(items, randomize=False):\n",
    "    k=n_folds\n",
    "    if randomize:\n",
    "        items = list(items)\n",
    "        shuffle(items)\n",
    "    slices = [items[i::k] for i in range(k)]\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation:` This function splits the data and resamples it for K fold cross validation\n",
    "\n",
    "# Loading Data\n",
    "`Story`\n",
    "\n",
    "Now, Adi asks you to define a function to load the data as well as convert data types into float.\n",
    "\n",
    "`How?`\n",
    "\n",
    "You first apply file handling principles to open the contents usign `with open(fname,'r') as f:`, and store those data into a list.\n",
    "\n",
    "Then you iterate through the list and erase all the extra spaces and lines, ad split according to commas.\n",
    "\n",
    "Adi hints you that The `strip()` method returns a copy of the string by removing both the leading and the trailing characters (based on the string argument passed). The strip() method removes characters from both left and right based on the argument (a string specifying the set of characters to be removed).\n",
    "\n",
    "\n",
    "    txt = \"     banana     \"\n",
    "    x = txt.strip()\n",
    "    #x will be \"banana\"\n",
    "    \n",
    "    \n",
    "Example of `split`:\n",
    "\n",
    "    # Default splits at whitespace\n",
    "    txt = \"Welcome to the SKills, Data!\"\n",
    "    txt.split()\n",
    "    # Output:\n",
    "    # [\"Welcome\", \"to\", \"the\", \"Skills,\" \"Data!\"]\n",
    "\n",
    "    # You can specify where to split\n",
    "    txt = \"Welcome to the jungle, baby!\"\n",
    "        txt.split(\", \")\n",
    "    # Output:\n",
    "    # [\"Welcome to the Skills\", \"Data!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How?`\n",
    "\n",
    "`def data(fname):`\n",
    "\n",
    "This returns the dataset from the .txt format after each value being converted to float from string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data as well as converting the data into float value. \n",
    "def data(fname):\n",
    "    X,Z=list(),list()\n",
    "    with open(fname,'r') as f:\n",
    "        contents = f.readlines()\n",
    "        Z+= contents\n",
    "    for i in Z:\n",
    "        my_list = i.strip(\"\\n\").strip(\"\\r\").split(\",\")\n",
    "        X.append(my_list)\n",
    "        X = [[float(column) for column in row] for row in X]\n",
    "    return X\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation:` X contains the modified dataset.\n",
    "# Gini Index\n",
    "`Story`\n",
    "\n",
    "Now, Adi explains you about the `Gini Index` by telling you that The main idea of a decision tree is to identify the features which contain the most information regarding the target feature and then split the dataset along the values of these features such that the target feature values at the resulting nodes are as pure as possible. A feature that best separates the uncertainty from information about the target feature is said to be the most informative feature. The search process for a most informative feature goes on until we end up with pure leaf nodes.\n",
    "\n",
    "The process of building a decision tree involves asking a question at every instance and then continuing with the split- When there are multiple features that decide the target value of a particular instance, which feature should be chosen as the root node to start the splitting process? And in which order should we continue choosing the features at every further split at a node? Here comes the need to measure the informativeness of the features and use the feature with the most information as the feature to split the data on. This informativeness is given by a measure called ‘information gain’. And for this, we need to understand the entropy of the dataset.\n",
    "\n",
    "    Entropy: It is used to measure the impurity or randomness of a dataset. Imagine choosing a yellow ball from a box of just yellow balls (say 100 yellow balls). Then this box is said to have 0 entropy which implies 0 impurity or total purity.\n",
    "\n",
    "    Now, let’s say 30 of these balls are replaced by red and 20 by blue. If we now draw another ball from the box, the probability of drawing a yellow ball will drop from 1.0 to 0.5. Since the impurity has increased, entropy has also increased while purity has decreased. \n",
    "\n",
    "    Gini Index: It is calculated by subtracting the sum of squared probabilities of each class from one. It favors larger partitions and easy to implement whereas information gain favors smaller partitions with distinct values.\n",
    "    A feature with a lower Gini index is chosen for a split.\n",
    "    \n",
    "### Gini Index in Action\n",
    "\n",
    "Gini Index, also known as Gini impurity, calculates the amount of probability of a specific feature that is classified incorrectly when selected randomly. If all the elements are linked with a single class then it can be called pure.\n",
    "\n",
    "Let’s perceive the criterion of the Gini Index, like the properties of entropy, the Gini index varies between values 0 and 1, where 0 expresses the purity of classification, i.e. All the elements belong to a specified class or only one class exists there. And 1 indicates the random distribution of elements across various classes. The value of 0.5 of the Gini Index shows an equal distribution of elements over some classes.\n",
    "\n",
    "While designing the decision tree, the features possessing the least value of the Gini Index would get preferred.\n",
    "\n",
    "Adi then tells you that The classic CART algorithm uses the Gini Index for constructing the decision treem hence we will be using Gini index here.\n",
    "\n",
    "\n",
    "`How?`\n",
    "\n",
    "\n",
    "The Gini Index is calculated by subtracting the sum of the squared probabilities of each class from one. It favors larger partitions. Information Gain multiplies the probability of the class times the log (base=2) of that class probability. Information Gain favors smaller partitions with many distinct values.\n",
    "\n",
    "\n",
    "`def gini(groups,class_values):`\n",
    "\n",
    "This function calculates the gini index. \n",
    "The Gini index is the name of the cost function on the basis of which splitting in the dataset is done. The lower the value of the gini index the better the splitting is done. Lowest value being 0 and highest value being 1.\n",
    "This gini function has to be explained in detail. To find the attribute according to which the splitting has to be done along with the value of the attribute that helps splitting the data in two sets, this value is calculated. \n",
    "Given a group and the class_values (labels), we calculate the purity of data. We calculate the ratio of the rows having the same labels over the total number of rows in the group. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The formula of gini_index is:\n",
    "\n",
    "`gini_index=ratio*(1-ratio)`\n",
    "\n",
    "where the ratio is explained above. We sum all the gini_values for each group for a each class_value . This value is returned to the splitting routine which calculates the lowest gini_index value, thus calculates the attribute and the value for which the splitting should be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini(groups,class_values):\n",
    "\tgini_value = 0.0\n",
    "\tfor class_value in class_values:#for each class_value \n",
    "\t\tfor group in groups:\n",
    "\t\t\tnumber=0.0\n",
    "\t\t\tsize = len(group)\n",
    "\t\t\tif size == 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tfor row in group:\n",
    "\t\t\t\tif(row[-1]==class_value):\n",
    "\t\t\t\t\tnumber+=1 #number of rows having the same class_value\n",
    "\t\t\tratio= number/float(len(group))\n",
    "\t\t\t#ratio of the particular class value over the total set of the group\n",
    "\t\t\tgini_value += (ratio* (1.0 - ratio))#formula to calculate the gini index\n",
    "\treturn gini_value\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation`: This fucntion calculates and returns the gini index.\n",
    "# Accuracy\n",
    "`Story`\n",
    "\n",
    "Adi tells you now that you should be calculating the acccuracy as well, and tells you to proceed as follows.\n",
    "\n",
    "\n",
    "`def calculate_accuracy(dataset):`\n",
    "\n",
    "This is the function where the training and the testing data is formulated using each of the k folds of the dataset repeatedly. Each fold is made the testing set once when the other folds are kept as the training sets. The score for each arrangement is then obtained and the mean score is calculated which is the accuracy of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the data is split in accordance with the k_fold_cross_validation \n",
    "here the data that is already divided into folds is divided into testing and training data\n",
    "with every fold getting the chance of getting the testing data when the other folds are the training data.\n",
    "'''\n",
    "def calculate_accuracy(dataset):\n",
    "\tfolds=k_fold_cross_validation(dataset)\n",
    "\tscores = list()\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold_at_i = folds[i]\n",
    "\t\ttraining=list()\n",
    "\t\tfor j in range(n_folds):\n",
    "\t\t\tif j!=i:\n",
    "\t\t\t\ttraining.append(folds[j])\n",
    "\t\ttraining = sum(training, [])#removes the error for unhashable types\n",
    "\t\ttesting = list()#make a test data list\n",
    "\t\tfor row in fold_at_i:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\trow_copy[-1] = None#MAKE THE LABEL NONE AND THEN APPEND\n",
    "\t\t\ttesting.append(row_copy)#make the test set\n",
    "\t\tpredicted = decision_tree(training, testing)\n",
    "\t\tactual = [row[-1] for row in fold_at_i]\n",
    "\t\tcorrect_values = 0# Calculate accuracy percentage. pretty straightforward\n",
    "\t\tfor i in range(len(actual)):\n",
    "\t\t\tif (actual[i] == predicted[i]):\n",
    "\t\t\t\tcorrect_values += 1\n",
    "\t\taccuracy= correct_values / float(len(actual)) * 100.0\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation`: This function returns the accuracy by taking the dataset as the argument.\n",
    "\n",
    "Now adi asks you to define the split function as `def test_split(index, value, dataset):`\n",
    "\n",
    "`How?`\n",
    "This function is responsible for making the groups that are later send to the gini routine. It splits the data into left and right nodes, on the basis of whether the value in the chosen attribute of the particular row is lesser or greater than the value of the attribute in accordance to which the splitting is done. It returns with the groups that is send to gini for getting the gini index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting function\n",
    "After this, you have to define the splitting function`def splitting(dataset):`\n",
    "\n",
    "This is responsible for getting the perfect splitting. It uses the gini function and the test_split function to do so. \n",
    "We obtain the gini_index for each attribute in our dataset. This is done by taking the average of the values for each attribute and sending the value to the test_split that divides the data on the basis of that attribute. Then the groups that are formed are send to the def gini which calculates the gini value. The lowest value of gini is chosen and the splitting is done on the basis of that attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def splitting(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tnode_index=999\n",
    "\tnode_value=999\n",
    "\tnode_score=999\n",
    "\tnode_groups =None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t#all index values for all the attributes\n",
    "\t\tcount=0.0\n",
    "\t\tcount_row=0.0\n",
    "\t\tfor row in dataset:#here we take the average of the values in a attribute to split the data \n",
    "\t\t\tcount+=1\n",
    "\t\t\tcount_row=row[index]+count_row\n",
    "\t\tcount_row=count_row/count\n",
    "\t\tgroups=test_split(index,count_row,dataset)\n",
    "\t\tgini_value=gini(groups,class_values)\n",
    "\t\tif gini_value < node_score:#store the values based on which the gini value is the lowest and the splitting is done\n",
    "\t\t#on the basis of that attribute\n",
    "\t\t\t\tnode_index, node_value, node_score, node_groups = index, row[index], gini_value, groups\n",
    "\treturn {'i':node_index, 'value':node_value, 'div':node_groups}#return the dictionary containing the details \n",
    "\t#on the basis of which the splitting is done\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation`: Adi tells you that this function would return the node index and the dictionary containing the details on the basis of which splitting is done.\n",
    "\n",
    "\n",
    "# Create terminal node\n",
    "Now, Adi asks you to define the \n",
    "`def terminal_node(group):` which contains the last node of the tree that contains the label that has the most frequency in the group that the node has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value contains highest frequency label from groups\n",
    "def terminal_node(group):\n",
    "\toutcomes = [row[-1] for row in group]#this returns all the labels for the data and stores in the outcome list\n",
    "\tclassify=[0,0]\n",
    "\tfor out in outcomes:\n",
    "\t\tclassify[(int(out))]+=1\n",
    "\tif(classify[0]>classify[1]):\n",
    "\t\treturn 0\n",
    "\telse:\n",
    "\t\treturn 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation`: This function returns the terminal node\n",
    "\n",
    "# Create the child node\n",
    "\n",
    "Now you create the \n",
    "`def node_split(node,depth):` which is a recursive function. Makes the tree by calling the splitting function. Checks if the particular node is terminal or not according to certain conditions like the min_size and the max_depth or if there cant be any more splitting done as no left or right node exists which occurs when all the values in the attribute is greater or less that the particular avg value of the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def node_split(node,depth):\n",
    "\tleft, right = node['div']\n",
    "\tdel(node['div'])\n",
    "\t# check if there is no split and the data is coherent. If all the values in the attribute is greater or less that the particular avg value of the attribute\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = terminal_node(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth is achieved\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = terminal_node(left), terminal_node(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:#if the mininmum records in the data is less than or equal to the min_size. No splitting\n",
    "\t\tnode['left'] = terminal_node(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = splitting(left)#otherwise split the data further keeping in mind the min_size and the max_depth\n",
    "\t\tnode_split(node['left'], depth+1)\n",
    "\t# process right child same as above\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = terminal_node(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = splitting(right)\n",
    "\t\tnode_split(node['right'], depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are asked to `def output_from_tree(node, row):`\n",
    "\n",
    "This is used while making the predictions. This is done to traverse the tree to the terminal nodes to get the prediction that the test data belongs to. Th =e terminal node is returned that contains only the label that has the max frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction from the tree\n",
    "def output_from_tree(node, row):\n",
    "\tif row[node['i']] < node['value']:\n",
    "\t\tif (type(node['left'])== dict):#if there exists a node['left'] of type dict\n",
    "\t\t\treturn output_from_tree(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']#otherwise return the label depicted by the terminal node\n",
    "\telse:#same for the right side of the subtree\n",
    "\t\tif (type(node['right'])== dict):\n",
    "\t\t\treturn output_from_tree(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Interpretation`: This returns the predicitons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the tree\n",
    "`def decision_tree(train, test):`\n",
    "\n",
    "This is the function that helps in obtaining the prediction values of the algorithm for all the rows in the testing data set. It calls the splitting routine by sending the training data. The splitting function is explained later. Lets just say that it basically sends back the root node to the decision_tree for now which is sent to the node_split routine that formulate the rest of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classification and Regression Tree Algorithm\n",
    "def decision_tree(train, test):\n",
    "\troot= splitting(train)\n",
    "\tnode_split(root,1)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\tprediction = output_from_tree(root, row)\n",
    "\t\tpredictions.append(prediction)\n",
    "\t\tprint(prediction)\n",
    "       \n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you finally call the calculate accuracy function which practically had all the functionaality enclosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "Mean Accuracy: 84.697%\n"
     ]
    }
   ],
   "source": [
    "dataset = data(filename)\n",
    "scores = calculate_accuracy(dataset)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/(len(scores))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that the decision tree does a fine job with an accuracy of 85%.\n",
    "\n",
    "* Decision trees areEasy to understand and interpret, perfect for visual representation. This is an example of a white box model, which closely mimics the human decision-making process.\n",
    "* Can work with numerical and categorical features.\n",
    "* Requires little data preprocessing: no need for one-hot encoding, dummy variables, and so on.\n",
    "* Non-parametric model: no assumptions about the shape of data.\n",
    "* Fast for inference.\n",
    "* Feature selection happens automatically: unimportant features will not influence the result. The presence of features that depend on each other (multicollinearity) also doesn't affect the quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
